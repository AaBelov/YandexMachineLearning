{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['first_blood_time', 'first_blood_team', 'first_blood_player1',\n",
      "       'first_blood_player2', 'radiant_bottle_time', 'radiant_courier_time',\n",
      "       'radiant_flying_courier_time', 'radiant_first_ward_time',\n",
      "       'dire_bottle_time', 'dire_courier_time', 'dire_flying_courier_time',\n",
      "       'dire_first_ward_time'],\n",
      "      dtype='object')\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.3786           29.36s\n",
      "         2           1.3732           28.94s\n",
      "         3           1.3681           27.63s\n",
      "         4           1.3636           26.54s\n",
      "         5           1.3589           25.20s\n",
      "         6           1.3547           24.27s\n",
      "         7           1.3502           23.18s\n",
      "         8           1.3461           21.97s\n",
      "         9           1.3422           20.88s\n",
      "        10           1.3385           19.91s\n",
      "        20           1.3092           10.03s\n",
      "        30           1.2892            0.00s\n",
      "Time elapsed: 0:02:20.638795\n",
      "[mean: 0.66471, std: 0.00471, params: {'n_estimators': 10},\n",
      " mean: 0.68234, std: 0.00309, params: {'n_estimators': 20},\n",
      " mean: 0.68945, std: 0.00312, params: {'n_estimators': 30}]\n",
      "0.700208881661\n",
      "scaled\n",
      "[mean: 0.69508, std: 0.00294, params: {'C': 1.0000000000000001e-05},\n",
      " mean: 0.71127, std: 0.00234, params: {'C': 0.0001},\n",
      " mean: 0.71630, std: 0.00195, params: {'C': 0.001},\n",
      " mean: 0.71652, std: 0.00180, params: {'C': 0.01},\n",
      " mean: 0.71650, std: 0.00179, params: {'C': 0.10000000000000001},\n",
      " mean: 0.71650, std: 0.00178, params: {'C': 1.0},\n",
      " mean: 0.71650, std: 0.00178, params: {'C': 10.0},\n",
      " mean: 0.71650, std: 0.00178, params: {'C': 100.0},\n",
      " mean: 0.71650, std: 0.00178, params: {'C': 1000.0},\n",
      " mean: 0.71650, std: 0.00178, params: {'C': 10000.0},\n",
      " mean: 0.71650, std: 0.00178, params: {'C': 100000.0}]\n",
      "removed\n",
      "[mean: 0.69503, std: 0.00293, params: {'C': 1.0000000000000001e-05},\n",
      " mean: 0.71127, std: 0.00229, params: {'C': 0.0001},\n",
      " mean: 0.71634, std: 0.00190, params: {'C': 0.001},\n",
      " mean: 0.71656, std: 0.00175, params: {'C': 0.01},\n",
      " mean: 0.71654, std: 0.00174, params: {'C': 0.10000000000000001},\n",
      " mean: 0.71654, std: 0.00173, params: {'C': 1.0},\n",
      " mean: 0.71654, std: 0.00173, params: {'C': 10.0},\n",
      " mean: 0.71654, std: 0.00173, params: {'C': 100.0},\n",
      " mean: 0.71654, std: 0.00173, params: {'C': 1000.0},\n",
      " mean: 0.71654, std: 0.00173, params: {'C': 10000.0},\n",
      " mean: 0.71654, std: 0.00173, params: {'C': 100000.0}]\n",
      "number of unique heroes\n",
      "word bag\n",
      "[mean: 0.69915, std: 0.00304, params: {'C': 1.0000000000000001e-05},\n",
      " mean: 0.72502, std: 0.00261, params: {'C': 0.0001},\n",
      " mean: 0.74630, std: 0.00249, params: {'C': 0.001},\n",
      " mean: 0.75177, std: 0.00244, params: {'C': 0.01},\n",
      " mean: 0.75199, std: 0.00241, params: {'C': 0.10000000000000001},\n",
      " mean: 0.75198, std: 0.00240, params: {'C': 1.0},\n",
      " mean: 0.75198, std: 0.00240, params: {'C': 10.0},\n",
      " mean: 0.75198, std: 0.00240, params: {'C': 100.0},\n",
      " mean: 0.75198, std: 0.00240, params: {'C': 1000.0},\n",
      " mean: 0.75198, std: 0.00240, params: {'C': 10000.0},\n",
      " mean: 0.75198, std: 0.00240, params: {'C': 100000.0}]\n",
      "0.00362911441158 0.996370885588\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "import numpy as np\n",
    "from random import randint\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import time\n",
    "import datetime\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from pprint import pprint\n",
    "\n",
    "rawDataTrain = pd.read_csv(\"Downloads/features.csv\", index_col=\"match_id\")\n",
    "rawDataTest = pd.read_csv(\"Downloads/features_test.csv\", index_col=\"match_id\")\n",
    "\n",
    "trainX = rawDataTrain.ix[:,:\"dire_first_ward_time\"]\n",
    "trainy = rawDataTrain.ix[:,\"radiant_win\"]\n",
    "\n",
    "columnsWithMissingData = trainX.columns[trainX.count() != 97230] #magic number antipattern don't do that, I'm a bad person.\n",
    "print(columnsWithMissingData)\n",
    "trainX.fillna(0, inplace=True)\n",
    "\n",
    "cv = KFold(n=len(trainX), n_folds=5, shuffle=True)\n",
    "gbc = GradientBoostingClassifier(verbose=True)\n",
    "grid = {\"n_estimators\": [10, 20, 30]}\n",
    "gs = GridSearchCV(estimator = gbc, param_grid = grid, cv = cv, scoring = \"roc_auc\", n_jobs=-1) #n_jobs sets number of threads. \n",
    "                                                                                            #Verbose=True doesn't work when \n",
    "                                                                                            #n_jobs != 1 for obvious reasons.\n",
    "start_time = datetime.datetime.now()\n",
    "gs.fit(trainX, trainy)\n",
    "print('Time elapsed:', datetime.datetime.now() - start_time)\n",
    "pprint(gs.grid_scores_)\n",
    "\n",
    "gbc = GradientBoostingClassifier(n_estimators=30)\n",
    "gbc.fit(trainX, trainy)\n",
    "pred = gbc.predict_proba(trainX)[:, 1]\n",
    "print(roc_auc_score(y_true = trainy, y_score = pred))\n",
    "\n",
    "sc = StandardScaler()\n",
    "trainX_scaled = pd.DataFrame(sc.fit_transform(trainX))\n",
    "trainX_scaled.columns = trainX.columns\n",
    "\n",
    "lrm = LogisticRegression(penalty = \"l2\")\n",
    "grid = {'C': np.power(10.0, np.arange(-5, 6))}\n",
    "gs = GridSearchCV(estimator = lrm, param_grid = grid, cv = cv, scoring = \"roc_auc\", n_jobs=-1)\n",
    "\n",
    "gs.fit(trainX_scaled, trainy)\n",
    "print(\"scaled\")\n",
    "pprint(gs.grid_scores_)\n",
    "\n",
    "\n",
    "cols = [col for col in trainX_scaled.columns if col not in ['lobby_type', 'r1_hero', 'r2_hero', 'r3_hero', 'r4_hero', 'r5_hero', 'd1_hero', 'd2_hero', 'd3_hero', 'd4_hero', 'd5_hero']]\n",
    "trainX_scaled_Removed = trainX_scaled[cols]\n",
    "\n",
    "lrm = LogisticRegression(penalty = \"l2\")\n",
    "gs.fit(trainX_scaled_Removed, trainy)\n",
    "print(\"removed\")\n",
    "pprint(gs.grid_scores_)\n",
    "\n",
    "allHeroes = []\n",
    "allHeroes = trainX.r1_hero.unique()\n",
    "allHeroes = np.concatenate((allHeroes, trainX.r2_hero.unique(), trainX.r3_hero.unique(), trainX.r4_hero.unique(), \n",
    "trainX.r5_hero.unique(), trainX.d1_hero.unique(), trainX.d2_hero.unique(), trainX.d3_hero.unique(), trainX.d4_hero.unique(), \n",
    "trainX.d5_hero.unique())) #I am a python master\n",
    "\n",
    "costylDF = pd.DataFrame(allHeroes)\n",
    "\n",
    "costylColumn = costylDF[0]\n",
    "uniqueHeroes = np.sort(costylColumn.unique())\n",
    "print(\"number of unique heroes\", len(uniqueHeroes))\n",
    "\n",
    "X_pick = np.zeros((trainX.shape[0], np.max(uniqueHeroes)))\n",
    "\n",
    "for i, match_id in enumerate(trainX.index):\n",
    "    for p in [0, 1, 2, 3, 4]:\n",
    "        X_pick[i, trainX.ix[match_id, 'r%d_hero' % (p+1)]-1] = 1\n",
    "        X_pick[i, trainX.ix[match_id, 'd%d_hero' % (p+1)]-1] = -1\n",
    "        \n",
    "trainX_scaled_meshok_slov_dobavled = np.hstack((trainX_scaled_Removed, X_pick))\n",
    "\n",
    "lrm = LogisticRegression(penalty=\"l2\")\n",
    "\n",
    "gs.fit(trainX_scaled_meshok_slov_dobavled, trainy)\n",
    "print(\"word bag\")\n",
    "pprint(gs.grid_scores_)\n",
    "\n",
    "testX = rawDataTest.fillna(0)\n",
    "testX_scaled = pd.DataFrame(sc.transform(testX))\n",
    "testX_scaled.columns = rawDataTest.columns\n",
    "cols = [col for col in testX_scaled.columns if col not in ['lobby_type', 'r1_hero', 'r2_hero', 'r3_hero', 'r4_hero', 'r5_hero', 'd1_hero', 'd2_hero', 'd3_hero', 'd4_hero', 'd5_hero']]\n",
    "testX_scaled_Removed = testX_scaled[cols]\n",
    "\n",
    "X_pick = np.zeros((testX.shape[0], np.max(uniqueHeroes)))\n",
    "\n",
    "for i, match_id in enumerate(testX.index):\n",
    "    for p in [0, 1, 2, 3, 4]:\n",
    "        X_pick[i, testX.ix[match_id, 'r%d_hero' % (p+1)]-1] = 1\n",
    "        X_pick[i, testX.ix[match_id, 'd%d_hero' % (p+1)]-1] = -1\n",
    "        \n",
    "testX_scaled_with_wordbag = np.hstack((testX_scaled_Removed, X_pick))\n",
    "y_pred = gs.predict_proba(testX_scaled_with_wordbag)\n",
    "print(np.min(y_pred), np.max(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00362911441158 0.996370885588\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of unique heroes 108\n"
     ]
    }
   ],
   "source": [
    "print(\"number of unique heroes\", len(uniqueHeroes))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
